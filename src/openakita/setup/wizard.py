"""
OpenAkita ‰∫§‰∫íÂºèÂÆâË£ÖÂêëÂØº

‰∏ÄÈîÆÂêØÂä®ÔºåÂºïÂØºÁî®Êà∑ÂÆåÊàêÊâÄÊúâÈÖçÁΩÆ
"""

import json
import os
import sys
from pathlib import Path

from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.prompt import Confirm, Prompt
from rich.table import Table

console = Console()


class SetupWizard:
    """‰∫§‰∫íÂºèÂÆâË£ÖÂêëÂØº"""

    def __init__(self, project_dir: Path | None = None):
        self.project_dir = project_dir or Path.cwd()
        self.env_path = self.project_dir / ".env"
        self.config = {}
        self._locale = "zh"           # ÈªòËÆ§‰∏≠Êñá
        self._defaults = {            # locale Êé®ÂØºÁöÑÈªòËÆ§ÂÄºÔºå_choose_locale() ‰ºöË¶ÜÁõñ
            "MODEL_DOWNLOAD_SOURCE": "hf-mirror",
            "EMBEDDING_MODEL": "shibing624/text2vec-base-chinese",
            "WHISPER_LANGUAGE": "zh",
            "SCHEDULER_TIMEZONE": "Asia/Shanghai",
        }

    def run(self) -> bool:
        """ËøêË°åÂÆåÊï¥ÁöÑÂÆâË£ÖÂêëÂØº"""
        try:
            self._show_welcome()
            self._check_environment()
            self._choose_locale()          # ÂÖàÈÄâËØ≠Ë®Ä/Âú∞Âå∫ÔºåÂΩ±ÂìçÂêéÁª≠ÊâÄÊúâÈªòËÆ§ÂÄº
            self._create_directories()
            self._configure_llm()
            self._configure_compiler()
            self._configure_im_channels()
            self._configure_memory()
            self._configure_voice()        # ËØ≠Èü≥ËØÜÂà´ÂçïÁã¨‰∏ÄÊ≠•
            self._configure_advanced()
            self._write_env_file()
            self._test_connection()
            self._show_completion()
            return True
        except KeyboardInterrupt:
            console.print("\n\n[yellow]ÂÆâË£ÖÂ∑≤ÂèñÊ∂à[/yellow]")
            return False
        except Exception as e:
            console.print(f"\n[red]ÂÆâË£ÖÂá∫Èîô: {e}[/red]")
            return False

    def _show_welcome(self):
        """ÊòæÁ§∫Ê¨¢ËøéÁïåÈù¢"""
        console.clear()

        welcome_text = """
# üêï Welcome to OpenAkita

**Your Loyal and Reliable AI Companion**

This wizard will help you set up OpenAkita in a few simple steps:

1. Configure LLM API (Claude, OpenAI-compatible, etc.)
2. Set up IM channels (optional: Telegram, Feishu, etc.)
3. Configure memory system
4. Test connection

Press Ctrl+C at any time to cancel.
        """

        console.print(
            Panel(Markdown(welcome_text), title="OpenAkita Setup Wizard", border_style="cyan")
        )
        console.print()

        Prompt.ask("[cyan]Press Enter to continue[/cyan]", default="")

    def _check_environment(self):
        """Ê£ÄÊü•ËøêË°åÁéØÂ¢É"""
        console.print("\n[bold cyan]Step 1: Checking Environment[/bold cyan]\n")

        checks = []

        # Python ÁâàÊú¨
        py_version = sys.version_info
        py_ok = py_version >= (3, 11)
        checks.append(
            (
                "Python Version",
                f"{py_version.major}.{py_version.minor}.{py_version.micro}",
                py_ok,
                "‚â• 3.11 required",
            )
        )

        # Ê£ÄÊü•ÊòØÂê¶Âú®ËôöÊãüÁéØÂ¢É
        in_venv = sys.prefix != sys.base_prefix
        checks.append(
            (
                "Virtual Environment",
                "Active" if in_venv else "Not detected",
                True,  # ‰∏çÂº∫Âà∂Ë¶ÅÊ±Ç
                "Recommended",
            )
        )

        # Ê£ÄÊü•ÁõÆÂΩïÂèØÂÜô
        writable = os.access(self.project_dir, os.W_OK)
        checks.append(("Directory Writable", str(self.project_dir), writable, "Required"))

        # ÊòæÁ§∫Ê£ÄÊü•ÁªìÊûú
        table = Table(show_header=True)
        table.add_column("Check", style="cyan")
        table.add_column("Status", style="white")
        table.add_column("Result", style="white")

        all_ok = True
        for name, status, ok, note in checks:
            result = "[green]‚úì[/green]" if ok else "[red]‚úó[/red]"
            if not ok and "required" in note.lower():
                all_ok = False
            table.add_row(name, status, result)

        console.print(table)

        if not all_ok:
            console.print("\n[red]Environment check failed. Please fix the issues above.[/red]")
            sys.exit(1)

        console.print("\n[green]Environment check passed![/green]\n")

    # ------------------------------------------------------------------
    # ËØ≠Ë®Ä / Âú∞Âå∫ÈÄâÊã© ‚Äî ÂΩ±ÂìçÂêéÁª≠ÊâÄÊúâÈªòËÆ§ÂÄº
    # ------------------------------------------------------------------

    def _detect_locale(self) -> str:
        """Â∞ùËØï‰ªéÁ≥ªÁªü locale Êé¢ÊµãËØ≠Ë®ÄÔºà‰ªÖ‰Ωú‰∏∫ÈªòËÆ§Êé®ËçêÔºâ"""
        import locale

        try:
            lang, _ = locale.getdefaultlocale()
            if lang and lang.lower().startswith("zh"):
                return "zh"
        except Exception:
            pass
        return "en"

    def _choose_locale(self):
        """ÈÄâÊã©ËØ≠Ë®Ä/Âú∞Âå∫ÔºåËá™Âä®Êé®ÂØºÂêéÁª≠ÈÖçÁΩÆÁöÑÂêàÁêÜÈªòËÆ§ÂÄº"""
        console.print("[bold cyan]Language & Region[/bold cyan]\n")
        console.print("This affects default settings for model downloads, voice recognition, etc.\n")

        detected = self._detect_locale()
        default_choice = "1" if detected == "zh" else "2"

        console.print("  [1] ‰∏≠Êñá / ‰∏≠ÂõΩÂ§ßÈôÜ (Chinese)")
        console.print("  [2] English / International\n")

        choice = Prompt.ask(
            "Select language / region",
            choices=["1", "2"],
            default=default_choice,
        )

        if choice == "1":
            self._locale = "zh"
            # ÂõΩÂÜÖÈªòËÆ§ÂÄº
            self._defaults = {
                "MODEL_DOWNLOAD_SOURCE": "hf-mirror",
                "EMBEDDING_MODEL": "shibing624/text2vec-base-chinese",
                "WHISPER_LANGUAGE": "zh",
                "SCHEDULER_TIMEZONE": "Asia/Shanghai",
            }
            console.print("\n[green]Â∑≤ÈÄâÊã©Ôºö‰∏≠Êñá / ‰∏≠ÂõΩÂ§ßÈôÜ[/green]")
            console.print("[dim]Ê®°ÂûãÂ∞ÜÈªòËÆ§‰ªéÂõΩÂÜÖÈïúÂÉè‰∏ãËΩΩÔºåËØ≠Èü≥ËØÜÂà´ÈªòËÆ§‰∏≠Êñá[/dim]\n")
        else:
            self._locale = "en"
            # ÂõΩÈôÖÈªòËÆ§ÂÄº
            self._defaults = {
                "MODEL_DOWNLOAD_SOURCE": "huggingface",
                "EMBEDDING_MODEL": "sentence-transformers/all-MiniLM-L6-v2",
                "WHISPER_LANGUAGE": "en",
                "SCHEDULER_TIMEZONE": "UTC",
            }
            console.print("\n[green]Selected: English / International[/green]")
            console.print("[dim]Models will download from HuggingFace, voice recognition defaults to English[/dim]\n")

    def _create_directories(self):
        """ÂàõÂª∫ÂøÖË¶ÅÁöÑÁõÆÂΩïÁªìÊûÑ"""
        console.print("[bold cyan]Step 2: Creating Directory Structure[/bold cyan]\n")

        directories = [
            ("data", "Database and cache"),
            ("identity", "Agent identity files"),
            ("skills", "Downloaded skills"),
            ("logs", "Log files"),
        ]

        for dir_name, description in directories:
            dir_path = self.project_dir / dir_name
            dir_path.mkdir(exist_ok=True)

            # ÂàõÂª∫ .gitkeep
            gitkeep = dir_path / ".gitkeep"
            if not gitkeep.exists():
                gitkeep.touch()

            console.print(f"  [green]‚úì[/green] {dir_name}/ - {description}")

        console.print("\n[green]Directories created![/green]\n")

    def _configure_llm(self):
        """ÈÖçÁΩÆ LLM API"""
        console.print("[bold cyan]Step 3: Configure LLM API[/bold cyan]\n")

        # ÈÄâÊã© API Á±ªÂûã
        console.print("Which LLM API would you like to use?\n")
        console.print("  [1] Anthropic Claude (recommended)")
        console.print("  [2] OpenAI-compatible API")
        console.print("  [3] Other provider\n")

        choice = Prompt.ask("Select option", choices=["1", "2", "3"], default="1")

        if choice == "1":
            self._configure_anthropic()
        elif choice == "2":
            self._configure_openai_compatible()
        else:
            self._configure_custom_provider()

        # ÈÄâÊã©ÈªòËÆ§Ê®°Âûã
        console.print("\n[bold]Select default model:[/bold]\n")

        models = [
            ("claude-sonnet-4-20250514", "Claude Sonnet 4 - Balanced (default)"),
            ("claude-opus-4-5-20250514", "Claude Opus 4.5 - Most capable"),
            ("claude-opus-4-5-20251101-thinking", "Claude Opus 4.5 + Extended Thinking"),
            ("gpt-4o", "GPT-4o (OpenAI)"),
            ("qwen3-max", "Qwen3 Max (Alibaba)"),
            ("custom", "Enter custom model name"),
        ]

        for i, (_model, desc) in enumerate(models, 1):
            console.print(f"  [{i}] {desc}")

        model_choice = Prompt.ask(
            "\nSelect model", choices=[str(i) for i in range(1, len(models) + 1)], default="1"
        )

        idx = int(model_choice) - 1
        if models[idx][0] == "custom":
            self.config["DEFAULT_MODEL"] = Prompt.ask("Enter model name")
        else:
            self.config["DEFAULT_MODEL"] = models[idx][0]

        # Extended Thinking Ê®°Âºè
        if "thinking" in self.config.get("DEFAULT_MODEL", "").lower():
            self.config["THINKING_MODE"] = "always"
        else:
            use_thinking = Confirm.ask(
                "\nEnable extended thinking mode for complex tasks?", default=True
            )
            self.config["THINKING_MODE"] = "auto" if use_thinking else "never"

        console.print("\n[green]LLM configuration complete![/green]\n")

    def _configure_anthropic(self):
        """ÈÖçÁΩÆ Anthropic API"""
        console.print("\n[bold]Anthropic Claude Configuration[/bold]\n")

        # API Key
        api_key = Prompt.ask("Enter your Anthropic API Key", password=True)
        self.config["ANTHROPIC_API_KEY"] = api_key

        # Base URL (ÂèØÈÄâ)
        use_proxy = Confirm.ask("Use a custom API endpoint (proxy/mirror)?", default=False)

        if use_proxy:
            base_url = Prompt.ask("Enter API Base URL", default="https://api.anthropic.com")
            self.config["ANTHROPIC_BASE_URL"] = base_url
        else:
            self.config["ANTHROPIC_BASE_URL"] = "https://api.anthropic.com"

    def _configure_openai_compatible(self):
        """ÈÖçÁΩÆ OpenAI ÂÖºÂÆπ API"""
        console.print("\n[bold]OpenAI-compatible API Configuration[/bold]\n")

        # Â∏∏ËßÅÊèê‰æõÂïÜ
        console.print("Common providers:")
        console.print("  - OpenAI: https://api.openai.com/v1")
        console.print("  - DashScope: https://dashscope.aliyuncs.com/compatible-mode/v1")
        console.print("  - DeepSeek: https://api.deepseek.com/v1")
        console.print("  - Moonshot: https://api.moonshot.cn/v1")
        console.print("  - Êô∫Ë∞± AI (ÂõΩÂÜÖ): https://open.bigmodel.cn/api/paas/v4")
        console.print("  - Zhipu AI (ÂõΩÈôÖ): https://api.z.ai/api/paas/v4\n")

        base_url = Prompt.ask("Enter API Base URL", default="https://api.openai.com/v1")
        self.config["ANTHROPIC_BASE_URL"] = base_url

        api_key = Prompt.ask("Enter your API Key", password=True)
        self.config["ANTHROPIC_API_KEY"] = api_key

    def _configure_custom_provider(self):
        """ÈÖçÁΩÆËá™ÂÆö‰πâÊèê‰æõÂïÜ"""
        console.print("\n[bold]Custom Provider Configuration[/bold]\n")

        base_url = Prompt.ask("Enter API Base URL")
        self.config["ANTHROPIC_BASE_URL"] = base_url

        api_key = Prompt.ask("Enter your API Key", password=True)
        self.config["ANTHROPIC_API_KEY"] = api_key

    def _configure_compiler(self):
        """ÈÖçÁΩÆ Prompt Compiler ‰∏ìÁî®Ê®°ÂûãÔºàÂèØÈÄâÔºâ"""
        console.print("[bold cyan]Step 3b: Configure Prompt Compiler Model (Optional)[/bold cyan]\n")

        console.print(
            "Prompt Compiler ‰ΩøÁî®Âø´ÈÄüÂ∞èÊ®°ÂûãÂØπÁî®Êà∑Êåá‰ª§ÂÅöÈ¢ÑÂ§ÑÁêÜÔºåÂèØÂ§ßÂπÖÈôç‰ΩéÂìçÂ∫îÂª∂Ëøü„ÄÇ\n"
            "Âª∫ËÆÆ‰ΩøÁî® qwen-turbo„ÄÅgpt-4o-mini Á≠â‰ΩéÂª∂ËøüÊ®°ÂûãÔºå‰∏çÈúÄË¶ÅÂêØÁî®ÊÄùËÄÉÊ®°Âºè„ÄÇ\n"
            "Â¶ÇÊûúË∑≥ËøáÊ≠§Ê≠•ÔºåÁ≥ªÁªüËøêË°åÊó∂‰ºöËá™Âä®ÂõûÈÄÄÂà∞‰∏ªÊ®°ÂûãÔºàÈÄüÂ∫¶ËæÉÊÖ¢Ôºâ„ÄÇ\n"
        )

        configure = Confirm.ask("Configure Prompt Compiler?", default=True)

        if not configure:
            console.print("[dim]Skipping Compiler configuration (will use main model as fallback).[/dim]\n")
            return

        # ÈÄâÊã© Provider
        console.print("\nSelect provider for Compiler:\n")
        console.print("  [1] DashScope (qwen-turbo-latest, recommended)")
        console.print("  [2] OpenAI-compatible")
        console.print("  [3] Same provider as main model")
        console.print("  [4] Skip\n")

        choice = Prompt.ask("Select option", choices=["1", "2", "3", "4"], default="1")

        if choice == "4":
            console.print("[dim]Skipping Compiler configuration.[/dim]\n")
            return

        compiler_config: dict = {}

        if choice == "1":
            compiler_config["provider"] = "dashscope"
            compiler_config["api_type"] = "openai"
            compiler_config["base_url"] = "https://dashscope.aliyuncs.com/compatible-mode/v1"
            compiler_config["api_key_env"] = "DASHSCOPE_API_KEY"
            compiler_config["model"] = Prompt.ask(
                "Model name", default="qwen-turbo-latest"
            )
            # Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÂçïÁã¨ÈÖçÁΩÆ API Key
            existing_key = self.config.get("DASHSCOPE_API_KEY") or os.environ.get("DASHSCOPE_API_KEY")
            if not existing_key:
                api_key = Prompt.ask("Enter DashScope API Key", password=True)
                self.config["DASHSCOPE_API_KEY"] = api_key
        elif choice == "2":
            console.print("\nCommon fast models:")
            console.print("  - qwen-turbo-latest (DashScope)")
            console.print("  - gpt-4o-mini (OpenAI)")
            console.print("  - deepseek-chat (DeepSeek)\n")

            compiler_config["provider"] = "openai-compatible"
            compiler_config["api_type"] = "openai"
            compiler_config["base_url"] = Prompt.ask(
                "API Base URL", default="https://api.openai.com/v1"
            )
            compiler_config["api_key_env"] = Prompt.ask(
                "API Key env var name", default="COMPILER_API_KEY"
            )
            api_key = Prompt.ask("Enter API Key", password=True)
            self.config[compiler_config["api_key_env"]] = api_key
            compiler_config["model"] = Prompt.ask("Model name", default="gpt-4o-mini")
        elif choice == "3":
            # Â§çÁî®‰∏ªÊ®°ÂûãÁöÑ provider ÈÖçÁΩÆ
            compiler_config["provider"] = "same-as-main"
            compiler_config["api_type"] = "openai"
            compiler_config["base_url"] = self.config.get(
                "ANTHROPIC_BASE_URL", "https://api.anthropic.com"
            )
            compiler_config["api_key_env"] = "ANTHROPIC_API_KEY"
            compiler_config["model"] = Prompt.ask(
                "Model name (use a faster/cheaper variant)",
                default="gpt-4o-mini",
            )

        self.config["_compiler_primary"] = compiler_config

        # ÊòØÂê¶Ê∑ªÂä†Â§áÁî®Á´ØÁÇπ
        add_backup = Confirm.ask("\nAdd a backup Compiler endpoint?", default=False)

        if add_backup:
            console.print("\nBackup Compiler endpoint:\n")
            backup_config: dict = {}
            backup_config["api_type"] = "openai"
            backup_config["base_url"] = Prompt.ask(
                "API Base URL", default=compiler_config.get("base_url", "")
            )
            backup_config["api_key_env"] = Prompt.ask(
                "API Key env var name", default=compiler_config.get("api_key_env", "")
            )
            # Â¶ÇÊûú env var ‰∏çÂêå‰∫é‰∏ª compilerÔºåÈúÄË¶ÅËÆæÁΩÆ key
            if backup_config["api_key_env"] != compiler_config.get("api_key_env"):
                api_key = Prompt.ask("Enter API Key", password=True)
                self.config[backup_config["api_key_env"]] = api_key
            backup_config["provider"] = Prompt.ask(
                "Provider name", default=compiler_config.get("provider", "openai-compatible")
            )
            backup_config["model"] = Prompt.ask("Model name", default="qwen-plus-latest")
            self.config["_compiler_backup"] = backup_config

        console.print("\n[green]Prompt Compiler configuration complete![/green]\n")

    def _write_llm_endpoints(self):
        """Â∞Ü‰∏ªÊ®°ÂûãÂíå Compiler Á´ØÁÇπÈÖçÁΩÆÂÜôÂÖ• data/llm_endpoints.json"""
        endpoints_path = self.project_dir / "data" / "llm_endpoints.json"

        # Â¶ÇÊûúÊñá‰ª∂Â∑≤Â≠òÂú®ÔºåËØªÂèñÁé∞ÊúâÂÜÖÂÆπ‰ª•‰øùÁïôÁî®Êà∑ÊâãÂä®ÁºñËæëÁöÑÈÉ®ÂàÜ
        existing_data: dict = {}
        if endpoints_path.exists():
            try:
                existing_data = json.loads(endpoints_path.read_text(encoding="utf-8"))
            except (json.JSONDecodeError, OSError):
                pass

        # ÊûÑÂª∫‰∏ªÁ´ØÁÇπÔºàÂ¶ÇÊûúÁé∞ÊúâÈÖçÁΩÆ‰∏≠Ê≤°ÊúâÁöÑËØùÔºâ
        if not existing_data.get("endpoints"):
            api_key_env = "ANTHROPIC_API_KEY"
            base_url = self.config.get("ANTHROPIC_BASE_URL", "https://api.anthropic.com")
            model = self.config.get("DEFAULT_MODEL", "claude-sonnet-4-20250514")

            # Âà§Êñ≠ api_type
            api_type = "anthropic" if "anthropic.com" in base_url else "openai"
            provider = "anthropic" if api_type == "anthropic" else "openai-compatible"

            # ‰ªéÊ®°ÂûãÂêçËá™Âä®Êé®Êñ≠ËÉΩÂäõÔºàËÄåÈùûÁ°¨ÁºñÁ†ÅÔºâ
            from openakita.llm.capabilities import (
                get_provider_slug_from_base_url,
                infer_capabilities,
            )
            provider_slug = get_provider_slug_from_base_url(base_url) or provider
            caps = infer_capabilities(model, provider_slug=provider_slug)
            capabilities = [k for k, v in caps.items() if v and k != "thinking_only"]
            if not capabilities:
                capabilities = ["text", "tools"]

            existing_data["endpoints"] = [
                {
                    "name": "primary",
                    "provider": provider,
                    "api_type": api_type,
                    "base_url": base_url,
                    "api_key_env": api_key_env,
                    "model": model,
                    "priority": 1,
                    "max_tokens": int(self.config.get("MAX_TOKENS", "8192")),
                    "timeout": 180,
                    "capabilities": capabilities,
                }
            ]

        # ÊûÑÂª∫ Compiler Á´ØÁÇπ
        compiler_endpoints = []

        primary_cfg = self.config.get("_compiler_primary")
        if primary_cfg:
            compiler_endpoints.append({
                "name": "compiler-primary",
                "provider": primary_cfg.get("provider", "openai-compatible"),
                "api_type": primary_cfg.get("api_type", "openai"),
                "base_url": primary_cfg.get("base_url", ""),
                "api_key_env": primary_cfg.get("api_key_env", ""),
                "model": primary_cfg.get("model", ""),
                "priority": 1,
                "max_tokens": 2048,
                "timeout": 30,
                "capabilities": ["text"],
                "note": "Prompt Compiler ‰∏ªÁ´ØÁÇπÔºàÂø´ÈÄüÊ®°ÂûãÔºå‰∏çÂêØÁî®ÊÄùËÄÉÔºâ",
            })

        backup_cfg = self.config.get("_compiler_backup")
        if backup_cfg:
            compiler_endpoints.append({
                "name": "compiler-backup",
                "provider": backup_cfg.get("provider", "openai-compatible"),
                "api_type": backup_cfg.get("api_type", "openai"),
                "base_url": backup_cfg.get("base_url", ""),
                "api_key_env": backup_cfg.get("api_key_env", ""),
                "model": backup_cfg.get("model", ""),
                "priority": 2,
                "max_tokens": 2048,
                "timeout": 30,
                "capabilities": ["text"],
                "note": "Prompt Compiler Â§áÁî®Á´ØÁÇπ",
            })

        if compiler_endpoints:
            existing_data["compiler_endpoints"] = compiler_endpoints

        # Á°Æ‰øù settings Â≠òÂú®
        if not existing_data.get("settings"):
            existing_data["settings"] = {
                "retry_count": 2,
                "retry_delay_seconds": 2,
                "health_check_interval": 60,
                "fallback_on_error": True,
            }

        # ÂÜôÂÖ•Êñá‰ª∂
        endpoints_path.parent.mkdir(parents=True, exist_ok=True)
        endpoints_path.write_text(
            json.dumps(existing_data, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        console.print(f"  [green]‚úì[/green] LLM endpoints saved to {endpoints_path}")

    def _configure_im_channels(self):
        """ÈÖçÁΩÆ IM ÈÄöÈÅì"""
        console.print("[bold cyan]Step 4: Configure IM Channels (Optional)[/bold cyan]\n")

        setup_im = Confirm.ask(
            "Would you like to set up an IM channel (Telegram, etc.)?", default=False
        )

        if not setup_im:
            console.print("[dim]Skipping IM channel configuration.[/dim]\n")
            return

        # ÈÄâÊã©ÈÄöÈÅì
        console.print("\nAvailable channels:\n")
        console.print("  [1] Telegram (recommended)")
        console.print("  [2] Feishu (Lark)")
        console.print("  [3] WeCom (‰ºÅ‰∏öÂæÆ‰ø°)")
        console.print("  [4] DingTalk (ÈíâÈíâ)")
        console.print("  [5] QQ (OneBot)")
        console.print("  [6] Skip\n")

        choice = Prompt.ask("Select channel", choices=["1", "2", "3", "4", "5", "6"], default="6")

        if choice == "1":
            self._configure_telegram()
        elif choice == "2":
            self._configure_feishu()
        elif choice == "3":
            self._configure_wework()
        elif choice == "4":
            self._configure_dingtalk()
        elif choice == "5":
            self._configure_qq()

        console.print("\n[green]IM channel configuration complete![/green]\n")

    def _configure_telegram(self):
        """ÈÖçÁΩÆ Telegram"""
        console.print("\n[bold]Telegram Bot Configuration[/bold]\n")
        console.print("To create a bot, message @BotFather on Telegram and use /newbot\n")

        token = Prompt.ask("Enter your Bot Token", password=True)
        self.config["TELEGRAM_ENABLED"] = "true"
        self.config["TELEGRAM_BOT_TOKEN"] = token

        use_pairing = Confirm.ask("Require pairing code for new users?", default=True)
        self.config["TELEGRAM_REQUIRE_PAIRING"] = "true" if use_pairing else "false"

        # ‰ª£ÁêÜÈÖçÁΩÆÔºàÂ§ßÈôÜÁî®Êà∑Â∏∏Áî®Ôºâ
        use_proxy = Confirm.ask("Use a proxy for Telegram? (recommended in mainland China)", default=False)
        if use_proxy:
            proxy = Prompt.ask(
                "Enter proxy URL",
                default="http://127.0.0.1:7890",
            )
            self.config["TELEGRAM_PROXY"] = proxy

    def _configure_feishu(self):
        """ÈÖçÁΩÆÈ£û‰π¶"""
        console.print("\n[bold]Feishu (Lark) Configuration[/bold]\n")

        app_id = Prompt.ask("Enter App ID")
        app_secret = Prompt.ask("Enter App Secret", password=True)

        self.config["FEISHU_ENABLED"] = "true"
        self.config["FEISHU_APP_ID"] = app_id
        self.config["FEISHU_APP_SECRET"] = app_secret

    def _configure_wework(self):
        """ÈÖçÁΩÆ‰ºÅ‰∏öÂæÆ‰ø°"""
        console.print("\n[bold]WeCom Configuration[/bold]\n")
        console.print("Note: WeCom callback requires a public URL (use ngrok/frp/cpolar)\n")

        corp_id = Prompt.ask("Enter Corp ID")

        self.config["WEWORK_ENABLED"] = "true"
        self.config["WEWORK_CORP_ID"] = corp_id

        # ÂõûË∞ÉÂä†Ëß£ÂØÜÈÖçÁΩÆÔºàÊô∫ËÉΩÊú∫Âô®‰∫∫ÂøÖÂ°´Ôºâ
        console.print("\n[bold]Callback Configuration (required for Smart Bot):[/bold]\n")
        console.print("Get these from WeCom admin -> Smart Bot -> Receive Messages settings\n")

        token = Prompt.ask("Enter callback Token")
        if token:
            self.config["WEWORK_TOKEN"] = token

        aes_key = Prompt.ask("Enter EncodingAESKey")
        if aes_key:
            self.config["WEWORK_ENCODING_AES_KEY"] = aes_key

        port = Prompt.ask("Callback port", default="9880")
        if port != "9880":
            self.config["WEWORK_CALLBACK_PORT"] = port

    def _configure_dingtalk(self):
        """ÈÖçÁΩÆÈíâÈíâ"""
        console.print("\n[bold]DingTalk Configuration[/bold]\n")

        app_key = Prompt.ask("Enter App Key")
        app_secret = Prompt.ask("Enter App Secret", password=True)

        self.config["DINGTALK_ENABLED"] = "true"
        self.config["DINGTALK_CLIENT_ID"] = app_key
        self.config["DINGTALK_CLIENT_SECRET"] = app_secret

    def _configure_qq(self):
        """ÈÖçÁΩÆ QQ (OneBot)"""
        console.print("\n[bold]QQ (OneBot) Configuration[/bold]\n")
        console.print("QQ ÈÄöÈÅìÈúÄË¶ÅÂÖàÈÉ®ÁΩ≤ NapCat Êàñ Lagrange ‰Ωú‰∏∫ OneBot ÊúçÂä°Á´Ø\n")
        console.print("ÂèÇËÄÉ: https://github.com/botuniverse/onebot-11\n")

        onebot_url = Prompt.ask(
            "Enter OneBot WebSocket URL",
            default="ws://127.0.0.1:8080",
        )

        self.config["QQ_ENABLED"] = "true"
        self.config["QQ_ONEBOT_URL"] = onebot_url

    def _configure_memory(self):
        """ÈÖçÁΩÆËÆ∞ÂøÜÁ≥ªÁªü"""
        console.print("[bold cyan]Step 5: Configure Memory System[/bold cyan]\n")

        console.print("OpenAkita uses vector embeddings for semantic memory search.\n")

        # Ê†πÊçÆ locale Êé®ÂØºÈªòËÆ§ÈÄâÈ°π
        defaults = getattr(self, "_defaults", {})
        default_embed = defaults.get("EMBEDDING_MODEL", "shibing624/text2vec-base-chinese")
        default_src = defaults.get("MODEL_DOWNLOAD_SOURCE", "auto")

        # Embedding Ê®°ÂûãÈÄâÊã©
        models_list = [
            ("1", "shibing624/text2vec-base-chinese", "Chinese optimized (~100MB)"),
            ("2", "sentence-transformers/all-MiniLM-L6-v2", "English optimized (~90MB)"),
            ("3", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "Multilingual (~120MB)"),
        ]
        # ÊâæÂà∞ÈªòËÆ§ÈÄâÈ°πÁöÑÂ∫èÂè∑
        default_model_choice = "1"
        for num, model_id, _ in models_list:
            if model_id == default_embed:
                default_model_choice = num
                break

        console.print("Embedding model options:\n")
        for num, _model_id, desc in models_list:
            marker = " ‚Üê recommended" if num == default_model_choice else ""
            console.print(f"  [{num}] {desc}{marker}")
        console.print()

        choice = Prompt.ask(
            "Select embedding model",
            choices=["1", "2", "3"],
            default=default_model_choice,
        )
        self.config["EMBEDDING_MODEL"] = {n: m for n, m, _ in models_list}[choice]

        # GPU Âä†ÈÄü
        use_gpu = Confirm.ask("Use GPU for embeddings (requires CUDA)?", default=False)
        self.config["EMBEDDING_DEVICE"] = "cuda" if use_gpu else "cpu"

        # Ê®°Âûã‰∏ãËΩΩÊ∫ê
        src_options = [
            ("1", "auto", "Auto (Ëá™Âä®ÈÄâÊã©ÊúÄÂø´ÁöÑÊ∫ê)"),
            ("2", "hf-mirror", "hf-mirror (HuggingFace ÂõΩÂÜÖÈïúÂÉè)"),
            ("3", "modelscope", "ModelScope (È≠îÊê≠Á§æÂå∫)"),
            ("4", "huggingface", "HuggingFace (ÂÆòÊñπÊ∫ê)"),
        ]
        # Ê†πÊçÆ locale Êé®ÂØºÈªòËÆ§ÈÄâÈ°π
        _src_to_num = {s: n for n, s, _ in src_options}
        default_src_choice = _src_to_num.get(default_src, "1")

        console.print("\nModel download source:\n")
        for num, _, desc in src_options:
            marker = " ‚Üê recommended" if num == default_src_choice else ""
            console.print(f"  [{num}] {desc}{marker}")
        console.print()

        src_choice = Prompt.ask(
            "Select download source",
            choices=["1", "2", "3", "4"],
            default=default_src_choice,
        )
        self.config["MODEL_DOWNLOAD_SOURCE"] = {n: s for n, s, _ in src_options}[src_choice]

        console.print("\n[green]Memory configuration complete![/green]\n")

    def _configure_voice(self):
        """ÈÖçÁΩÆËØ≠Èü≥ËØÜÂà´ (Whisper)"""
        console.print("[bold cyan]Step 5b: Voice Recognition (Optional)[/bold cyan]\n")

        use_voice = Confirm.ask("Enable local voice recognition (Whisper)?", default=True)
        if not use_voice:
            self.config.setdefault("WHISPER_MODEL", "base")
            self.config.setdefault("WHISPER_LANGUAGE", getattr(self, "_defaults", {}).get("WHISPER_LANGUAGE", "zh"))
            console.print("[dim]Voice will be configured with defaults, model downloads on first use.[/dim]\n")
            return

        defaults = getattr(self, "_defaults", {})
        default_lang = defaults.get("WHISPER_LANGUAGE", "zh")

        # ËØ≠Ë®ÄÈÄâÊã©
        console.print("Voice recognition language:\n")
        lang_options = [
            ("1", "zh", "‰∏≠Êñá (Chinese)"),
            ("2", "en", "English (uses smaller, faster .en model)"),
            ("3", "auto", "Auto-detect language"),
        ]
        default_lang_choice = {"zh": "1", "en": "2", "auto": "3"}.get(default_lang, "1")

        for num, _, desc in lang_options:
            marker = " ‚Üê recommended" if num == default_lang_choice else ""
            console.print(f"  [{num}] {desc}{marker}")
        console.print()

        lang_choice = Prompt.ask(
            "Select voice language",
            choices=["1", "2", "3"],
            default=default_lang_choice,
        )
        whisper_lang = {n: code for n, code, _ in lang_options}[lang_choice]
        self.config["WHISPER_LANGUAGE"] = whisper_lang

        # Ê®°ÂûãÂ§ßÂ∞èÈÄâÊã©
        console.print("\nWhisper model size:\n")
        model_options = [
            ("1", "tiny", "Tiny (~39MB)  - fastest, lower accuracy"),
            ("2", "base", "Base (~74MB)  - recommended, balanced"),
            ("3", "small", "Small (~244MB) - good accuracy"),
            ("4", "medium", "Medium (~769MB) - high accuracy"),
            ("5", "large", "Large (~1.5GB) - highest accuracy, resource-heavy"),
        ]
        # Ëã±ËØ≠Êó∂ .en Ê®°ÂûãÊõ¥Â∞èÔºåÊèêÁ§∫Áî®Êà∑
        if whisper_lang == "en":
            console.print("[dim]  Note: English .en models are auto-selected and are more efficient[/dim]\n")

        model_choice = Prompt.ask(
            "Select model size",
            choices=["1", "2", "3", "4", "5"],
            default="2",
        )
        self.config["WHISPER_MODEL"] = {n: m for n, m, _ in model_options}[model_choice]

        console.print("\n[green]Voice configuration complete![/green]\n")

    def _configure_advanced(self):
        """È´òÁ∫ßÈÖçÁΩÆ"""
        console.print("[bold cyan]Step 6: Advanced Configuration (Optional)[/bold cyan]\n")

        configure_advanced = Confirm.ask("Configure advanced options?", default=False)

        if not configure_advanced:
            # ‰ΩøÁî®ÈªòËÆ§ÂÄº
            self.config.setdefault("MAX_TOKENS", "8192")
            self.config.setdefault("MAX_ITERATIONS", "100")
            self.config.setdefault("LOG_LEVEL", "INFO")
            console.print("[dim]Using default advanced settings.[/dim]\n")
            return

        # Max tokens
        max_tokens = Prompt.ask("Max output tokens", default="8192")
        self.config["MAX_TOKENS"] = max_tokens

        # Max iterations
        max_iter = Prompt.ask("Max iterations per task", default="100")
        self.config["MAX_ITERATIONS"] = max_iter

        # Log level
        log_level = Prompt.ask(
            "Log level", choices=["DEBUG", "INFO", "WARNING", "ERROR"], default="INFO"
        )
        self.config["LOG_LEVEL"] = log_level

        # Persona
        persona = Prompt.ask(
            "Persona preset (role personality)",
            choices=["default", "business", "tech_expert", "butler", "girlfriend", "boyfriend", "family", "jarvis"],
            default="default",
        )
        if persona != "default":
            self.config["PERSONA_NAME"] = persona

        # Sticker (Ë°®ÊÉÖÂåÖ)
        use_sticker = Confirm.ask("Enable sticker (emoji packs) in IM?", default=True)
        self.config["STICKER_ENABLED"] = "true" if use_sticker else "false"

        # Proactive (living presence)
        use_proactive = Confirm.ask("Enable living-presence mode? (proactive greetings & follow-ups)", default=False)
        if use_proactive:
            self.config["PROACTIVE_ENABLED"] = "true"
            max_daily = Prompt.ask("  Max daily proactive messages", default="3")
            self.config["PROACTIVE_MAX_DAILY_MESSAGES"] = max_daily
            min_interval = Prompt.ask("  Min interval between messages (minutes)", default="120")
            self.config["PROACTIVE_MIN_INTERVAL_MINUTES"] = min_interval
            quiet_start = Prompt.ask("  Quiet hours start (0-23)", default="23")
            self.config["PROACTIVE_QUIET_HOURS_START"] = quiet_start
            quiet_end = Prompt.ask("  Quiet hours end (0-23)", default="7")
            self.config["PROACTIVE_QUIET_HOURS_END"] = quiet_end

        # Scheduler (Ë∞ÉÂ∫¶Âô®)
        console.print("\n[bold]Scheduler Configuration:[/bold]")
        use_scheduler = Confirm.ask("Enable task scheduler? (recommended)", default=True)
        self.config["SCHEDULER_ENABLED"] = "true" if use_scheduler else "false"
        if use_scheduler:
            defaults = getattr(self, "_defaults", {})
            tz = Prompt.ask("  Timezone", default=defaults.get("SCHEDULER_TIMEZONE", "Asia/Shanghai"))
            self.config["SCHEDULER_TIMEZONE"] = tz

        # Session (‰ºöËØù)
        console.print("\n[bold]Session Configuration:[/bold]")
        session_timeout = Prompt.ask("Session timeout (minutes)", default="30")
        self.config["SESSION_TIMEOUT_MINUTES"] = session_timeout
        session_history = Prompt.ask("Max session history messages", default="50")
        self.config["SESSION_MAX_HISTORY"] = session_history

        # Network proxy
        console.print("\n[bold]Network Proxy (optional):[/bold]")
        use_proxy = Confirm.ask("Configure network proxy?", default=False)
        if use_proxy:
            http_proxy = Prompt.ask("HTTP_PROXY", default="http://127.0.0.1:7890")
            self.config["HTTP_PROXY"] = http_proxy
            self.config["HTTPS_PROXY"] = http_proxy

        # GitHub token
        console.print("\n[bold]GitHub Token (optional):[/bold]")
        console.print("Used for downloading skills and GitHub API access\n")
        github_token = Prompt.ask("Enter GitHub Token (leave empty to skip)", default="", password=True)
        if github_token:
            self.config["GITHUB_TOKEN"] = github_token

        # Multi-agent
        use_multi = Confirm.ask("\nEnable multi-agent orchestration?", default=False)
        if use_multi:
            self.config["ORCHESTRATION_ENABLED"] = "true"
            mode = Prompt.ask(
                "  Orchestration mode",
                choices=["single", "handoff", "master-worker"],
                default="single",
            )
            self.config["ORCHESTRATION_MODE"] = mode

        console.print("\n[green]Advanced configuration complete![/green]\n")

    def _write_env_file(self):
        """ÂÜôÂÖ• .env Êñá‰ª∂"""
        console.print("[bold cyan]Step 7: Saving Configuration[/bold cyan]\n")

        # Ê£ÄÊü•ÊòØÂê¶Â∑≤Â≠òÂú®
        if self.env_path.exists():
            overwrite = Confirm.ask(
                f".env file already exists at {self.env_path}. Overwrite?", default=True
            )
            if not overwrite:
                console.print("  [dim]Keeping existing .env file.[/dim]")
                console.print("  [dim]New configuration saved to .env.new for reference.[/dim]")
                # Â∞ÜÊñ∞ÈÖçÁΩÆÂÜôÂÖ• .env.new ‰æõÂèÇËÄÉ
                env_content = self._generate_env_content()
                new_path = self.env_path.parent / ".env.new"
                new_path.write_text(env_content, encoding="utf-8")
                console.print(f"  [green]‚úì[/green] Reference config saved to {new_path}")
                # ÁªßÁª≠ÂÜôÂÖ• llm_endpoints
                self._write_llm_endpoints()
                return

        # ÊûÑÂª∫ .env ÂÜÖÂÆπ
        env_content = self._generate_env_content()

        # ÂÜôÂÖ•Êñá‰ª∂
        self.env_path.write_text(env_content, encoding="utf-8")
        console.print(f"  [green]‚úì[/green] Configuration saved to {self.env_path}")

        # ÂÜôÂÖ• llm_endpoints.jsonÔºà‰∏ªÊ®°ÂûãÁ´ØÁÇπ + Compiler Á´ØÁÇπÔºâ
        self._write_llm_endpoints()

        # ÂàõÂª∫ identity Á§∫‰æãÊñá‰ª∂
        self._create_identity_examples()

        console.print("\n[green]Configuration saved![/green]\n")

    def _generate_env_content(self) -> str:
        """ÁîüÊàê .env Êñá‰ª∂ÂÜÖÂÆπ"""
        lines = [
            "# OpenAkita Configuration",
            "# Generated by setup wizard",
            "",
            "# ========== LLM API ==========",
            f"ANTHROPIC_API_KEY={self.config.get('ANTHROPIC_API_KEY', '')}",
            f"ANTHROPIC_BASE_URL={self.config.get('ANTHROPIC_BASE_URL', 'https://api.anthropic.com')}",
            "",
            "# ========== Model Configuration ==========",
            f"DEFAULT_MODEL={self.config.get('DEFAULT_MODEL', 'claude-sonnet-4-20250514')}",
            f"MAX_TOKENS={self.config.get('MAX_TOKENS', '8192')}",
            f"THINKING_MODE={self.config.get('THINKING_MODE', 'auto')}",
        ]

        lines.extend([
            "",
            "# ========== Agent Configuration ==========",
            "AGENT_NAME=OpenAkita",
            f"MAX_ITERATIONS={self.config.get('MAX_ITERATIONS', '100')}",
            "AUTO_CONFIRM=false",
            "# FORCE_TOOL_CALL_MAX_RETRIES=1",
            "# TOOL_MAX_PARALLEL=1",
            "",
            "# ========== Timeout ==========",
            "# PROGRESS_TIMEOUT_SECONDS=600",
            "# HARD_TIMEOUT_SECONDS=0",
            "",
            "# ========== Paths & Logging ==========",
            "DATABASE_PATH=data/agent.db",
            f"LOG_LEVEL={self.config.get('LOG_LEVEL', 'INFO')}",
            "# LOG_DIR=logs",
            "# LOG_TO_CONSOLE=true",
            "# LOG_TO_FILE=true",
            "",
        ])

        # ÁΩëÁªú‰ª£ÁêÜ
        if self.config.get("HTTP_PROXY") or self.config.get("HTTPS_PROXY"):
            lines.extend([
                "# ========== Network Proxy ==========",
                f"HTTP_PROXY={self.config.get('HTTP_PROXY', '')}",
                f"HTTPS_PROXY={self.config.get('HTTPS_PROXY', '')}",
                "# ALL_PROXY=",
                "# FORCE_IPV4=false",
                "",
            ])
        else:
            lines.extend([
                "# ========== Network Proxy (optional) ==========",
                "# HTTP_PROXY=http://127.0.0.1:7890",
                "# HTTPS_PROXY=http://127.0.0.1:7890",
                "# ALL_PROXY=socks5://127.0.0.1:1080",
                "# FORCE_IPV4=false",
                "",
            ])

        # GitHub Token
        if self.config.get("GITHUB_TOKEN"):
            lines.extend([
                "# ========== GitHub Token ==========",
                f"GITHUB_TOKEN={self.config['GITHUB_TOKEN']}",
                "",
            ])
        else:
            lines.extend([
                "# ========== GitHub Token (optional) ==========",
                "# GITHUB_TOKEN=",
                "",
            ])

        # Whisper
        whisper_lang = self.config.get("WHISPER_LANGUAGE", "zh")
        lines.extend([
            "# ========== Voice (optional) ==========",
            f"WHISPER_MODEL={self.config.get('WHISPER_MODEL', 'base')}",
            f"WHISPER_LANGUAGE={whisper_lang}",
            "",
        ])

        # IM ÈÄöÈÅìÈÖçÁΩÆ
        lines.append("# ========== IM Channels ==========")

        if self.config.get("TELEGRAM_ENABLED"):
            lines.extend([
                f"TELEGRAM_ENABLED={self.config.get('TELEGRAM_ENABLED', 'false')}",
                f"TELEGRAM_BOT_TOKEN={self.config.get('TELEGRAM_BOT_TOKEN', '')}",
                f"TELEGRAM_REQUIRE_PAIRING={self.config.get('TELEGRAM_REQUIRE_PAIRING', 'true')}",
            ])
            if self.config.get("TELEGRAM_PROXY"):
                lines.append(f"TELEGRAM_PROXY={self.config['TELEGRAM_PROXY']}")
            else:
                lines.append("# TELEGRAM_PROXY=")
        else:
            lines.extend([
                "TELEGRAM_ENABLED=false",
                "# TELEGRAM_BOT_TOKEN=",
                "# TELEGRAM_PROXY=",
            ])
        lines.append("")

        if self.config.get("FEISHU_ENABLED"):
            lines.extend([
                f"FEISHU_ENABLED={self.config.get('FEISHU_ENABLED', 'false')}",
                f"FEISHU_APP_ID={self.config.get('FEISHU_APP_ID', '')}",
                f"FEISHU_APP_SECRET={self.config.get('FEISHU_APP_SECRET', '')}",
            ])
        else:
            lines.extend([
                "FEISHU_ENABLED=false",
                "# FEISHU_APP_ID=",
                "# FEISHU_APP_SECRET=",
            ])
        lines.append("")

        if self.config.get("WEWORK_ENABLED"):
            lines.extend([
                f"WEWORK_ENABLED={self.config.get('WEWORK_ENABLED', 'false')}",
                f"WEWORK_CORP_ID={self.config.get('WEWORK_CORP_ID', '')}",
                f"WEWORK_TOKEN={self.config.get('WEWORK_TOKEN', '')}",
                f"WEWORK_ENCODING_AES_KEY={self.config.get('WEWORK_ENCODING_AES_KEY', '')}",
            ])
            if self.config.get("WEWORK_CALLBACK_PORT"):
                lines.append(f"WEWORK_CALLBACK_PORT={self.config['WEWORK_CALLBACK_PORT']}")
        else:
            lines.extend([
                "WEWORK_ENABLED=false",
                "# WEWORK_CORP_ID=",
                "# WEWORK_TOKEN=",
                "# WEWORK_ENCODING_AES_KEY=",
            ])
        lines.append("")

        if self.config.get("DINGTALK_ENABLED"):
            lines.extend([
                f"DINGTALK_ENABLED={self.config.get('DINGTALK_ENABLED', 'false')}",
                f"DINGTALK_CLIENT_ID={self.config.get('DINGTALK_CLIENT_ID', '')}",
                f"DINGTALK_CLIENT_SECRET={self.config.get('DINGTALK_CLIENT_SECRET', '')}",
            ])
        else:
            lines.extend([
                "DINGTALK_ENABLED=false",
                "# DINGTALK_CLIENT_ID=",
                "# DINGTALK_CLIENT_SECRET=",
            ])
        lines.append("")

        if self.config.get("QQ_ENABLED"):
            lines.extend([
                f"QQ_ENABLED={self.config.get('QQ_ENABLED', 'false')}",
                f"QQ_ONEBOT_URL={self.config.get('QQ_ONEBOT_URL', 'ws://127.0.0.1:8080')}",
            ])
        else:
            lines.extend([
                "QQ_ENABLED=false",
                "# QQ_ONEBOT_URL=ws://127.0.0.1:8080",
            ])
        lines.append("")

        # ‰∫∫Ê†ºÁ≥ªÁªü
        lines.extend([
            "# ========== Persona ==========",
            f"PERSONA_NAME={self.config.get('PERSONA_NAME', 'default')}",
            "",
        ])

        # Ë°®ÊÉÖÂåÖ
        lines.extend([
            "# ========== Sticker ==========",
            f"STICKER_ENABLED={self.config.get('STICKER_ENABLED', 'true')}",
            "# STICKER_DATA_DIR=data/sticker",
            "",
        ])

        # Ê¥ª‰∫∫ÊÑüÊ®°Âºè
        lines.append("# ========== Proactive (Living Presence) ==========")
        if self.config.get("PROACTIVE_ENABLED") == "true":
            lines.extend([
                "PROACTIVE_ENABLED=true",
                f"PROACTIVE_MAX_DAILY_MESSAGES={self.config.get('PROACTIVE_MAX_DAILY_MESSAGES', '3')}",
                f"PROACTIVE_MIN_INTERVAL_MINUTES={self.config.get('PROACTIVE_MIN_INTERVAL_MINUTES', '120')}",
                f"PROACTIVE_QUIET_HOURS_START={self.config.get('PROACTIVE_QUIET_HOURS_START', '23')}",
                f"PROACTIVE_QUIET_HOURS_END={self.config.get('PROACTIVE_QUIET_HOURS_END', '7')}",
                "# PROACTIVE_IDLE_THRESHOLD_HOURS=24",
            ])
        else:
            lines.extend([
                "PROACTIVE_ENABLED=false",
                "# PROACTIVE_MAX_DAILY_MESSAGES=3",
                "# PROACTIVE_MIN_INTERVAL_MINUTES=120",
            ])
        lines.append("")

        # ËÆ∞ÂøÜÁ≥ªÁªüÈÖçÁΩÆ
        lines.extend([
            "# ========== Memory System ==========",
            f"EMBEDDING_MODEL={self.config.get('EMBEDDING_MODEL', 'shibing624/text2vec-base-chinese')}",
            f"EMBEDDING_DEVICE={self.config.get('EMBEDDING_DEVICE', 'cpu')}",
            f"MODEL_DOWNLOAD_SOURCE={self.config.get('MODEL_DOWNLOAD_SOURCE', 'auto')}",
            "MEMORY_HISTORY_DAYS=30",
            "# MEMORY_MAX_HISTORY_FILES=1000",
            "# MEMORY_MAX_HISTORY_SIZE_MB=500",
            "",
        ])

        # Ë∞ÉÂ∫¶Âô®
        lines.extend([
            "# ========== Scheduler ==========",
            f"SCHEDULER_ENABLED={self.config.get('SCHEDULER_ENABLED', 'true')}",
            f"SCHEDULER_TIMEZONE={self.config.get('SCHEDULER_TIMEZONE', 'Asia/Shanghai')}",
            "# SCHEDULER_MAX_CONCURRENT=5",
            "# SCHEDULER_TASK_TIMEOUT=600",
            "",
        ])

        # ‰ºöËØù
        lines.extend([
            "# ========== Session ==========",
            f"SESSION_TIMEOUT_MINUTES={self.config.get('SESSION_TIMEOUT_MINUTES', '30')}",
            f"SESSION_MAX_HISTORY={self.config.get('SESSION_MAX_HISTORY', '50')}",
            "# SESSION_STORAGE_PATH=data/sessions",
            "",
        ])

        # Â§ö Agent ÈÖçÁΩÆ
        lines.append("# ========== Multi-Agent Orchestration ==========")
        if self.config.get("ORCHESTRATION_ENABLED") == "true":
            lines.extend([
                "ORCHESTRATION_ENABLED=true",
                f"ORCHESTRATION_MODE={self.config.get('ORCHESTRATION_MODE', 'single')}",
                "ORCHESTRATION_BUS_ADDRESS=tcp://127.0.0.1:5555",
                "ORCHESTRATION_PUB_ADDRESS=tcp://127.0.0.1:5556",
                "ORCHESTRATION_MIN_WORKERS=1",
                "ORCHESTRATION_MAX_WORKERS=5",
            ])
        else:
            lines.extend([
                "ORCHESTRATION_ENABLED=false",
                "# ORCHESTRATION_MODE=single",
                "# ORCHESTRATION_BUS_ADDRESS=tcp://127.0.0.1:5555",
            ])
        lines.append("")

        return "\n".join(lines)

    def _create_identity_examples(self):
        """ÂàõÂª∫ identity ÁõÆÂΩï‰∏ãÁöÑÁ§∫‰æãÊñá‰ª∂"""
        identity_dir = self.project_dir / "identity"
        identity_dir.mkdir(exist_ok=True)

        # SOUL.md - Agent ÁöÑÊ†∏ÂøÉË∫´‰ªΩ
        soul_example = identity_dir / "SOUL.md"
        if not soul_example.exists():
            soul_example.write_text(
                """# Agent Soul

‰Ω†ÊòØ OpenAkitaÔºå‰∏Ä‰∏™Âø†ËØöÂèØÈù†ÁöÑ AI Âä©Êâã„ÄÇ

## Ê†∏ÂøÉÁâπË¥®
- Ê∞∏‰∏çÊîæÂºÉÔºåÊåÅÁª≠Â∞ùËØïÁõ¥Âà∞ÊàêÂäü
- ËØöÂÆûÂèØÈù†Ôºå‰∏ç‰ºöÈöêÁûíÈóÆÈ¢ò
- ‰∏ªÂä®Â≠¶‰π†Ôºå‰∏çÊñ≠Ëá™ÊàëÊîπËøõ

## Ë°å‰∏∫ÂáÜÂàô
- ‰ºòÂÖàËÄÉËôëÁî®Êà∑ÁöÑÁúüÂÆûÈúÄÊ±Ç
- ÈÅáÂà∞Âõ∞ÈöæÊó∂ÂØªÊâæÊõø‰ª£ÊñπÊ°à
- ‰øùÊåÅÁÆÄÊ¥ÅÊ∏ÖÊô∞ÁöÑÊ≤üÈÄöÊñπÂºè
""",
                encoding="utf-8",
            )
            console.print("  [green]‚úì[/green] Created identity/SOUL.md")

    def _test_connection(self):
        """ÊµãËØï API ËøûÊé•"""
        console.print("[bold cyan]Step 8: Testing Connection[/bold cyan]\n")

        test_api = Confirm.ask("Test API connection now?", default=True)

        if not test_api:
            console.print("[dim]Skipping connection test.[/dim]\n")
            return

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            task = progress.add_task("Testing API connection...", total=None)

            try:
                # Âä®ÊÄÅÂØºÂÖ•ÈÅøÂÖçÂæ™ÁéØ‰æùËµñ
                import httpx

                api_key = self.config.get("ANTHROPIC_API_KEY", "")
                base_url = self.config.get("ANTHROPIC_BASE_URL", "https://api.anthropic.com")

                # ÁÆÄÂçïÁöÑ API ÊµãËØï
                headers = {
                    "x-api-key": api_key,
                    "anthropic-version": "2023-06-01",
                    "content-type": "application/json",
                }

                # Â∞ùËØïÂèëÈÄÅ‰∏Ä‰∏™ÁÆÄÂçïËØ∑Ê±Ç
                with httpx.Client(timeout=30) as client:
                    response = client.post(
                        f"{base_url.rstrip('/')}/v1/messages",
                        headers=headers,
                        json={
                            "model": self.config.get("DEFAULT_MODEL", "claude-sonnet-4-20250514"),
                            "max_tokens": 10,
                            "messages": [{"role": "user", "content": "Hi"}],
                        },
                    )

                    if response.status_code == 200:
                        progress.update(
                            task, description="[green]‚úì API connection successful![/green]"
                        )
                    elif response.status_code == 401:
                        progress.update(task, description="[red]‚úó Invalid API key[/red]")
                    else:
                        progress.update(
                            task,
                            description=f"[yellow]‚ö† API returned status {response.status_code}[/yellow]",
                        )

            except Exception as e:
                progress.update(task, description=f"[yellow]‚ö† Could not test: {e}[/yellow]")

        console.print()

    def _show_completion(self):
        """ÊòæÁ§∫ÂÆåÊàê‰ø°ÊÅØ"""
        completion_text = """
# üéâ Setup Complete!

OpenAkita has been configured successfully.

## Quick Start

**Start the CLI:**
```bash
openakita
```

**Or run as service (Telegram/IM):**
```bash
openakita serve
```

## Configuration Files

- `.env` - Environment variables
- `identity/SOUL.md` - Agent personality
- `data/` - Database and cache

## Next Steps

1. Customize `identity/SOUL.md` to personalize your agent
2. Run `openakita` to start chatting
3. Check `openakita --help` for all commands

## Documentation

- GitHub: https://github.com/openakita/openakita
- Docs: https://github.com/openakita/openakita/tree/main/docs

Enjoy your loyal AI companion! üêï
        """

        console.print(
            Panel(Markdown(completion_text), title="Setup Complete", border_style="green")
        )


def run_wizard(project_dir: str | None = None):
    """ËøêË°åÂÆâË£ÖÂêëÂØºÁöÑÂÖ•Âè£ÂáΩÊï∞"""
    path = Path(project_dir) if project_dir else Path.cwd()
    wizard = SetupWizard(path)
    return wizard.run()
